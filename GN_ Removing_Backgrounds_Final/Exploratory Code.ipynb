{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model I suggest we use:\n",
    "\n",
    "|Model Name|Number of Features|Names of Features\n",
    "|--------------|---------|---------\n",
    "|Comb Model|25 |'mu_plus_ProbNNk', 'mu_plus_ProbNNe', 'mu_plus_ProbNNp', 'mu_minus_ProbNNk', 'mu_minus_ProbNNe', 'mu_minus_ProbNNp', 'K_ProbNNk', 'K_ProbNNpi', 'K_ProbNNmu', 'K_ProbNNe', 'Pi_ProbNNk', 'Pi_ProbNNmu', 'Pi_ProbNNe', 'Pi_ProbNNp', 'Pi_PT', 'Pi_IPCHI2_OWNPV', 'B0_ENDVERTEX_CHI2', 'B0_PT', 'Kstar_M', 'J_psi_M', 'B0_IPCHI2_OWNPV', 'B0_DIRA_OWNPV', 'B0_OWNPV_X', 'B0_OWNPV_Y', 'q2'\n",
    "|Peaking Model (Background Trained Together) |13 | 'K_ProbNNk', 'K_ProbNNpi', 'K_ProbNNp', 'Pi_ProbNNk', 'Pi_ProbNNpi', 'Pi_ProbNNp', 'Pi_PT', 'Pi_PX', 'Pi_IPCHI2_OWNPV', 'B0_M', 'Kstar_M', 'costhetal', 'costhetak'\n",
    "\n",
    "For Peaking Model (Background Trained Separately):\n",
    "\n",
    "|Model Name|Number of Features|Names of Features\n",
    "|--------------|---------|---------\n",
    "|jpsi_mu_k_swap|4 |'mu_plus_ProbNNk', 'mu_plus_ProbNNmu', 'K_ProbNNk', 'K_ProbNNmu'\n",
    "|jpsi_mu_pi_swap  |5|'mu_minus_ProbNNpi', 'mu_minus_ProbNNmu', 'Pi_ProbNNpi', 'Pi_ProbNNmu', 'costhetal'\n",
    "|k_pi_swap |5|'K_ProbNNk', 'K_ProbNNpi', 'Pi_ProbNNk', 'Pi_ProbNNpi', 'Pi_ProbNNp'\n",
    "|Kmumu|7|'Pi_PT', 'Pi_PX', 'Pi_IPCHI2_OWNPV', 'B0_M', 'B0_ENDVERTEX_CHI2', 'B0_OWNPV_Y', 'costhetak'\n",
    "|Kstarp_pi0 |7|'Pi_PT', 'Pi_PX', 'Pi_IPCHI2_OWNPV', 'B0_M', 'B0_ENDVERTEX_CHI2', 'Kstar_M', 'Kstar_ENDVERTEX_CHI2'\n",
    "|phimumu |7|'Pi_ProbNNk', 'Pi_ProbNNpi', 'Pi_ProbNNp', 'Pi_PT', 'B0_M', 'Kstar_M', 'costhetak'\n",
    "|pkmumu_piTok_kTop |6|'K_ProbNNk', 'K_ProbNNp', 'Pi_ProbNNk', 'Pi_ProbNNpi', 'B0_M', 'B0_OWNPV_Y'\n",
    "|pKmumu_piTop |8|'Pi_ProbNNk', 'Pi_ProbNNpi', 'Pi_ProbNNp', 'Pi_P', 'Pi_PE', 'B0_M', 'Kstar_M', 'B0_OWNPV_Y'\n",
    "\n",
    "\n",
    "\n",
    "We see grouping in the ROC_AUC_SCORE, to avoid over fitting when the score stops changing drastically we potentially can stop including more features.\n",
    "\n",
    "The ROC_AUC_SCORE is generally higher for separately trained models as they contain less data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "total_data = pd.read_csv('../data/total_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(dataset, reject_rows = []):\n",
    "    #'B0_M', 'J_psi_M', 'q2','Kstar_M'\n",
    "    dataset_modified = dataset.copy()\n",
    "    dataset_modified.drop(columns=['Unnamed: 0.1','Unnamed: 0', 'year', 'B0_ID', 'B0_ENDVERTEX_NDOF','J_psi_ENDVERTEX_NDOF', 'Kstar_ENDVERTEX_NDOF'], inplace=True)\n",
    "    if 'Unnamed: 0.2' in dataset_modified.columns:\n",
    "        dataset_modified.drop(columns=['Unnamed: 0.2'], inplace=True)\n",
    "\n",
    "    columns_list = dataset_modified.columns.tolist()\n",
    "    for x in reject_rows:\n",
    "        if x in columns_list:\n",
    "            dataset_modified.drop(columns=[x],inplace = True)\n",
    "    \n",
    "    return dataset_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_corrolation_list_peaking_separate(num,name_of_background):\n",
    "    corrolation = pd.read_csv('Peaking_Separate_Correlation/continuous_f1_score_{}.csv'.format(name_of_background))\n",
    "    cols = corrolation.columns.tolist()\n",
    "    values = {}\n",
    "    for x in cols:\n",
    "        values[x] = float(corrolation[x])\n",
    "\n",
    "    values = dict(sorted(values.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    array_list = []\n",
    "    for idx, key in enumerate(values):\n",
    "        if(idx > num-1):\n",
    "            array_list.append(key)\n",
    "    return array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_corrolation_list_peaking_together(num):\n",
    "    corrolation = pd.read_csv('Peaking_Together_Correlation/continuous_f1_score_peaking_together.csv')\n",
    "    cols = corrolation.columns.tolist()\n",
    "    values = {}\n",
    "    for x in cols:\n",
    "        values[x] = float(corrolation[x])\n",
    "\n",
    "    values = dict(sorted(values.items(), key=lambda item: item[1], reverse=True))\n",
    "    array_list = []\n",
    "    for idx, key in enumerate(values):\n",
    "        if(idx > num-1):\n",
    "            array_list.append(key)\n",
    "    return array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_corrolation_list_comb(num):\n",
    "    corrolation = pd.read_csv('Comb_Correlation/continuous_f1_score_comb.csv')\n",
    "    cols = corrolation.columns.tolist()\n",
    "    values = {}\n",
    "    for x in cols:\n",
    "        values[x] = float(corrolation[x])\n",
    "\n",
    "    values = dict(sorted(values.items(), key=lambda item: item[1], reverse=True))\n",
    "    array_list = []\n",
    "    for idx, key in enumerate(values):\n",
    "        if(idx > num-1):\n",
    "            array_list.append(key)\n",
    "    return array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pi_ProbNNk', 'Pi_ProbNNpi', 'Pi_ProbNNp', 'Pi_P', 'Pi_PE', 'B0_M', 'Kstar_M', 'B0_OWNPV_Y']\n"
     ]
    }
   ],
   "source": [
    "remove_columns_list = high_corrolation_list_peaking_separate(8,'pKmumu_piTop')\n",
    "data_frame = remove_columns(total_data,remove_columns_list)\n",
    "print(data_frame.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K_ProbNNk', 'K_ProbNNpi', 'K_ProbNNp', 'Pi_ProbNNk', 'Pi_ProbNNpi', 'Pi_ProbNNp', 'Pi_PT', 'Pi_PX', 'Pi_IPCHI2_OWNPV', 'B0_M', 'Kstar_M', 'costhetal', 'costhetak']\n"
     ]
    }
   ],
   "source": [
    "remove_columns_list = high_corrolation_list_peaking_together(13)\n",
    "data_frame = remove_columns(total_data,remove_columns_list)\n",
    "print(data_frame.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mu_plus_ProbNNk', 'mu_plus_ProbNNe', 'mu_plus_ProbNNp', 'mu_minus_ProbNNk', 'mu_minus_ProbNNe', 'mu_minus_ProbNNp', 'K_ProbNNk', 'K_ProbNNpi', 'K_ProbNNmu', 'K_ProbNNe', 'Pi_ProbNNk', 'Pi_ProbNNmu', 'Pi_ProbNNe', 'Pi_ProbNNp', 'Pi_PT', 'Pi_IPCHI2_OWNPV', 'B0_ENDVERTEX_CHI2', 'B0_PT', 'Kstar_M', 'J_psi_M', 'B0_IPCHI2_OWNPV', 'B0_DIRA_OWNPV', 'B0_OWNPV_X', 'B0_OWNPV_Y', 'q2']\n"
     ]
    }
   ],
   "source": [
    "remove_columns_list = high_corrolation_list_comb(25)\n",
    "remove_columns_list.append('B0_M')\n",
    "data_frame = remove_columns(total_data,remove_columns_list)\n",
    "print(data_frame.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9dd5217a0dde95d381641731e639fd09a35f02e990bc29f8ba4a4a2775dc0bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
