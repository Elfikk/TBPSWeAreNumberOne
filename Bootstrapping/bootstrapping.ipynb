{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import pandas as pd\n",
    "from iminuit import Minuit\n",
    "import scipy\n",
    "from chebyshev_fitting import Data\n",
    "from chebyshev_fitting import Accept\n",
    "import json\n",
    "from math import ceil\n",
    "from sklearn.utils import resample\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Change this to where acceptance is located\n",
    "df_accept = pd.read_csv('../data/acceptance_mc.csv') \n",
    "\n",
    "\n",
    "#Change this to where the ml signal is located\n",
    "df_data = pd.read_csv('ML_SIGNAL_BDT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_observables(df_data, verbose = False):\n",
    "    \n",
    "    \n",
    "    # df_data = pd.read_csv('signal.csv')\n",
    "    #%% Acceptance:\n",
    "\n",
    "    acceptance = Accept(df_accept)\n",
    "    data = Data(df_data)\n",
    "    bins = []\n",
    "    bin_edges = ([[0.1,0.98], [1.1,2.5], [2.5,4.0], [4.0,6.0], [6.0,8.0], [15.0,17.0], [17.0,19.0], [11.0,12.5], [1.0,6.0], [15.0,17.9]])\n",
    "\n",
    "    def bin_q2(dataframe,edges, bins):\n",
    "        '''\n",
    "        This function bins given data according to the input bin edges.\n",
    "        '''\n",
    "        for i in range(len(edges)):\n",
    "            df1 = dataframe[dataframe['q2']<edges[i][1]]\n",
    "            df1 = df1[df1['q2']>edges[i][0]]\n",
    "            bins.append(df1)\n",
    "                \n",
    "    bin_q2(df_data, bin_edges, bins)\n",
    "\n",
    "    poly_l_list = []\n",
    "    poly_k_list = []\n",
    "    poly_p_list = []\n",
    "    poly_q_list = []\n",
    "\n",
    "    #Uncomment your choice of polynomial\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(bin_edges)):\n",
    "        b = bin_edges[i]\n",
    "        poly_l = acceptance.chebyshev(\"costhetal\", b[0], b[1], order = 4, name = \"Data\", plot_p = 0, plot_poly = 0)[1]\n",
    "        poly_k = acceptance.chebyshev(\"costhetak\", b[0], b[1], order = 4, name = \"Data\", plot_p = 0, plot_poly = 0)[1]\n",
    "        poly_p = acceptance.chebyshev(\"phi\", b[0], b[1], order = 4, name = \"Data\", plot_p = 0, plot_poly = 0)[1]\n",
    "        poly_q = acceptance.chebyshevq(b[0], b[1], order = 5, name = \"Data\", plot_p = 0, plot_poly = 0)[1]\n",
    "        poly_l_list.append(poly_l)\n",
    "        poly_k_list.append(poly_k)\n",
    "        poly_p_list.append(poly_p)\n",
    "        poly_q_list.append(poly_q)\n",
    "\n",
    "    #%% Distributions: Theta - Phi\n",
    "\n",
    "    def ctl_dist(ctl,q2,fl,afb,_bin):\n",
    "        c2tl = 2*ctl**2 - 1\n",
    "        dist = 3/8 * (3/2 - 1/2*fl + 1/2*c2tl*(1-3*fl) + 8/3*afb*ctl)  \n",
    "        \n",
    "        poly_l = poly_l_list[int(_bin)]\n",
    "        poly_q = poly_q_list[int(_bin)]\n",
    "\n",
    "        acceptance_fn_l = poly_l[0] + poly_l[1]*ctl + poly_l[2]*ctl**2 + poly_l[3]*ctl**3 + poly_l[4]*ctl**4\n",
    "        acceptance_fn_q = poly_q[0] + poly_q[1]*q2 + poly_q[2]*q2**2 + poly_q[3]*q2**3 + poly_q[4]*q2**4 + poly_q[5]*q2**5\n",
    "\n",
    "        acceptance_fn = acceptance_fn_l*acceptance_fn_q\n",
    "    \n",
    "        normalised_dist = dist*acceptance_fn\n",
    "        return normalised_dist\n",
    "\n",
    "    def ctk_dist(ctk,q2,fl,_bin):\n",
    "        stk2 = 1-ctk**2\n",
    "        ctk2 = ctk**2\n",
    "        dist = 3/4 * ((1-fl)*stk2 + 2*fl*ctk2)\n",
    "        \n",
    "        poly_k = poly_k_list[int(_bin)]\n",
    "        poly_q = poly_q_list[int(_bin)]\n",
    "        \n",
    "        acceptance_fn_k = poly_k[0] + poly_k[1]*ctk + poly_k[2]*ctk**2 + poly_k[3]*ctk**3 + poly_k[4]*ctk**4\n",
    "        acceptance_fn_q = poly_q[0] + poly_q[1]*q2 + poly_q[2]*q2**2 + poly_q[3]*q2**3 + poly_q[4]*q2**4 + poly_q[5]*q2**5\n",
    "        \n",
    "        acceptance_fn = acceptance_fn_k*acceptance_fn_q\n",
    "        normalised_dist = dist*acceptance_fn\n",
    "        return normalised_dist\n",
    "    \n",
    "    def phi_dist(phi,q2,s3,s9,_bin):\n",
    "        dist = 1/(2*np.pi) * (1 + s3*np.cos(2*phi) + s9*np.sin(2*phi))\n",
    "        \n",
    "        poly_p = poly_p_list[int(_bin)]\n",
    "        poly_q = poly_q_list[int(_bin)]\n",
    "\n",
    "        acceptance_fn_p = poly_p[0] + poly_p[1]*phi + poly_p[2]*phi**2 + poly_p[3]*phi**3 + poly_p[4]*phi**4\n",
    "        acceptance_fn_q = poly_q[0] + poly_q[1]*q2 + poly_q[2]*q2**2 + poly_q[3]*q2**3 + poly_q[4]*q2**4 + poly_q[5]*q2**5\n",
    "\n",
    "        acceptance_fn = acceptance_fn_p*acceptance_fn_q\n",
    "        normalised_dist = dist*acceptance_fn\n",
    "        return normalised_dist\n",
    "\n",
    "    #%% Derived Quantities:\n",
    "        \n",
    "    def Ps(Ss, FLs, P):\n",
    "        for i in range(len(Ss)):\n",
    "            P.append(Ss[i]/(np.sqrt(1-FLs[i])))\n",
    "\n",
    "    def Ps_E(Ss, FLs, Ss_E, FLs_E,P_E):\n",
    "        for i in range(len(Ss)):\n",
    "            A = ((Ss_E[i])/(np.sqrt(1-FLs[i])))\n",
    "            B = (((Ss[i]*FLs_E[i])/2)*(1/(1-FLs[i])**(3/2)))\n",
    "            P_E.append(np.sqrt(A**2 + B**2))\n",
    "\n",
    "    #%% Log-likelihood:\n",
    "\n",
    "    costhetal = data.angle(\"costhetal\")\n",
    "    costhetak = data.angle(\"costhetak\")\n",
    "    d_phi = data.angle(\"phi\")\n",
    "    d_q2 = data.q2()\n",
    "\n",
    "\n",
    "    def log_likelihood(FL,AFB,S3,S4,S5,S7,S8,S9,_bin):\n",
    "        bbin = bins[int(_bin)]\n",
    "        ctl = bbin['costhetal']\n",
    "        ctk = bbin['costhetak']\n",
    "        phi = bbin['phi']\n",
    "        q2 =  bbin[\"q2\"]\n",
    "        P = dist(ctk,ctl,phi,q2,FL,AFB,S3,S4,S5,S7,S8,S9,_bin)\n",
    "        return - np.sum(np.log(P))\n",
    "\n",
    "    def decay_rate_eqn(ctk,ctl,phi,FL,AFB,S3,S4,S5,S7,S8,S9):\n",
    "        ctk2 = ctk**2    \n",
    "        ctl2 = ctl**2\n",
    "        s2k = 2* np.sqrt(1-ctk2)*ctk\n",
    "        s2l = 2* np.sqrt(1-ctl2)*ctl\n",
    "        A = 0.75*(1-FL)*(1-ctk2) + FL*(ctk2) + 0.25*(1-FL)*(1-ctk2)*((2*ctl2)-1)\n",
    "        B = -FL*(ctk2)*(2*ctl2-1) + S3*(1-ctk**2)*(1-ctl2)*np.cos(2*phi)\n",
    "        C = S4*s2k*s2l*np.cos(phi) + S5*s2k*(np.sqrt(1-ctl**2))*np.cos(phi)\n",
    "        D = (4/3)*AFB*(1-ctk2)*ctl + S7*s2k*(np.sqrt(1-ctl**2))*np.sin(phi)\n",
    "        E = S8*s2k*s2l*np.sin(phi) + S9*(1-ctk2)*(1-ctl2)*np.sin(2*phi)\n",
    "        F = (9/(32*np.pi))*(A+B+C+D+E)\n",
    "        return F\n",
    "\n",
    "    def dist(ctk,ctl,phi,q2,FL,AFB,S3,S4,S5,S7,S8,S9,_bin):\n",
    "        poly_l = poly_l_list[int(_bin)]\n",
    "        poly_k = poly_k_list[int(_bin)]\n",
    "        poly_p = poly_p_list[int(_bin)]\n",
    "        poly_q = poly_q_list[int(_bin)]\n",
    "        F = decay_rate_eqn(ctk,ctl,phi,FL,AFB,S3,S4,S5,S7,S8,S9)\n",
    "\n",
    "        acceptance_fn_l = poly_l[0] + poly_l[1]*ctl + poly_l[2]*ctl**2 + poly_l[3]*ctl**3 + poly_l[4]*ctl**4\n",
    "        acceptance_fn_k = poly_k[0] + poly_k[1]*ctk + poly_k[2]*ctk**2 + poly_k[3]*ctk**3 + poly_k[4]*ctk**4\n",
    "        acceptance_fn_p = poly_p[0] + poly_p[1]*phi + poly_p[2]*phi**2 + poly_p[3]*phi**3 + poly_p[4]*phi**4\n",
    "        acceptance_fn_q = poly_q[0] + poly_q[1]*q2 + poly_q[2]*q2**2 + poly_q[3]*q2**3 + poly_q[4]*q2**4 + poly_q[5]*q2**5\n",
    "        \n",
    "        acceptance_fn = acceptance_fn_l*acceptance_fn_k*acceptance_fn_p*acceptance_fn_q\n",
    "        normalised_dist = (F*acceptance_fn)\n",
    "        \n",
    "        return normalised_dist\n",
    "\n",
    "\n",
    "    #%% Initial Values:\n",
    "\n",
    "    bin0 = [0.296448,-0.097052,0.010876,0.090919,0.252907,-0.020672,-0.002153,-0.000701]\n",
    "    bin1 = [0.760396,-0.137987,0.002373,-0.025359,0.054524,-0.027117,-0.006877,-0.000786]\n",
    "    bin2 = [0.796265,-0.017385,-0.010864,-0.151610,-0.193015,-0.019962,-0.006587,-0.000735]\n",
    "    bin3 = [0.711290,0.122155,-0.024751,-0.224204,-0.337140,-0.013383,-0.005062,-0.000706]\n",
    "    bin4 = [0.606965,0.239939,-0.039754,-0.259699,-0.403554,-0.008738,-0.003689,-0.000715]\n",
    "    bin5 = [0.348441,0.401914,-0.173464,-0.294319,-0.318728,-0.001377,0.000323,0.000292]\n",
    "    bin6 = [0.328081,0.318391,-0.251488,-0.310007,-0.226258,-0.000561,0.000119,0.000169]\n",
    "    bin7 = [0.435190,0.391390,-0.085975,-0.281589,-0.406803,-0.002194,0.001051,0.000449]\n",
    "    bin8 = [0.747644,0.004929,-0.012641,-0.142821,-0.176674,-0.019362,-0.006046,-0.000739]\n",
    "    bin9 = [0.340156,0.367672,-0.204963,-0.300427,-0.280936,-0.001039,0.000240, 0.000242]\n",
    "\n",
    "    st=[bin0,bin1,bin2,bin3,bin4,bin5,bin6,bin7,bin8,bin9]\n",
    "\n",
    "    #%% Minimisation:\n",
    "\n",
    "\n",
    "    bin_number_to_check = [0,1,2,3,4,5,6,7,8,9]\n",
    "    bin_results_to_check = None\n",
    "\n",
    "    log_likelihood.errordef = Minuit.LIKELIHOOD\n",
    "    decimal_places = 3\n",
    "    starting_point = st\n",
    "\n",
    "    FLs, FLs_E = [], []\n",
    "    S3s, S3s_E = [], []\n",
    "    S4s, S4s_E = [], []\n",
    "    S5s, S5s_E = [], []\n",
    "    AFBs, AFBs_E = [], []\n",
    "    S7s, S7s_E = [], []\n",
    "    S8s, S8s_E = [], []\n",
    "    S9s, S9s_E = [], []\n",
    "\n",
    "    for i in bin_number_to_check:\n",
    "        if verbose == True:\n",
    "            print('Fitting for bin',i)\n",
    "        m = Minuit(log_likelihood, FL=st[i][0], AFB=st[i][1], S3=st[i][2], S4=st[i][3], S5=st[i][4],S7=st[i][5], S8=st[i][6], S9=st[i][7],  _bin = i)\n",
    "        m.fixed['_bin'] = True \n",
    "        m.limits=((-1.0, 1.0),(-1.0, 1.0),(-1.0, 1.0),(-1.0, 1.0),(-1.0, 1.0),(-1.0, 1.0),(-1.0, 1.0),(-1.0, 1.0), None)\n",
    "        m.migrad() \n",
    "        m.hesse() \n",
    "    \n",
    "        \n",
    "        FLs.append(m.values[0])\n",
    "        AFBs.append(m.values[1])\n",
    "        S3s.append(m.values[2])\n",
    "        S4s.append(m.values[3])\n",
    "        S5s.append(m.values[4])\n",
    "        S7s.append(m.values[5])\n",
    "        S8s.append(m.values[6])\n",
    "        S9s.append(m.values[7])\n",
    "        \n",
    "        FLs_E.append(m.errors[0])\n",
    "        AFBs_E.append(m.errors[1])\n",
    "        S3s_E.append(m.errors[2])\n",
    "        S4s_E.append(m.errors[3])\n",
    "        S5s_E.append(m.errors[4])\n",
    "        S7s_E.append(m.errors[5])\n",
    "        S8s_E.append(m.errors[6])\n",
    "        S9s_E.append(m.errors[7])\n",
    "    return FLs,AFBs,S3s,S4s,S5s,S7s,S8s,S9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToFile(file, msg):\n",
    "    f = open(file, 'a').write(msg+'\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ['Bin'+str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cells below are the only cells you really need to look at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL ONLY ONCE TO CREATE THE INITAL FILES!!!!!\n",
    "\n",
    "\n",
    "\n",
    "# addToFile('Bootstrap_thread3/FLs.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/AFBs.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/S3s.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/S4s.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/S5s.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/S7s.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/S8s.csv',','.join(list(map(str,arr))))\n",
    "# addToFile('Bootstrap_thread3/S9s.csv',','.join(list(map(str,arr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 0\n",
      "SAMPLE 1\n",
      "SAMPLE 2\n",
      "SAMPLE 3\n",
      "SAMPLE 4\n",
      "SAMPLE 5\n",
      "SAMPLE 6\n",
      "SAMPLE 7\n",
      "SAMPLE 8\n",
      "SAMPLE 9\n",
      "SAMPLE 10\n",
      "SAMPLE 11\n",
      "SAMPLE 12\n",
      "SAMPLE 13\n",
      "SAMPLE 14\n",
      "SAMPLE 15\n",
      "SAMPLE 16\n",
      "SAMPLE 17\n",
      "SAMPLE 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Languages\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 19\n",
      "SAMPLE 20\n",
      "SAMPLE 21\n",
      "SAMPLE 22\n",
      "SAMPLE 23\n",
      "SAMPLE 24\n",
      "SAMPLE 25\n",
      "SAMPLE 26\n",
      "SAMPLE 27\n",
      "SAMPLE 28\n",
      "SAMPLE 29\n",
      "SAMPLE 30\n",
      "SAMPLE 31\n",
      "SAMPLE 32\n",
      "SAMPLE 33\n",
      "SAMPLE 34\n",
      "SAMPLE 35\n",
      "SAMPLE 36\n",
      "SAMPLE 37\n",
      "SAMPLE 38\n",
      "SAMPLE 39\n",
      "SAMPLE 40\n",
      "SAMPLE 41\n",
      "SAMPLE 42\n",
      "SAMPLE 43\n",
      "SAMPLE 44\n",
      "SAMPLE 45\n",
      "SAMPLE 46\n",
      "SAMPLE 47\n",
      "SAMPLE 48\n",
      "SAMPLE 49\n",
      "SAMPLE 50\n",
      "SAMPLE 51\n",
      "SAMPLE 52\n",
      "SAMPLE 53\n",
      "SAMPLE 54\n",
      "SAMPLE 55\n",
      "SAMPLE 56\n",
      "SAMPLE 57\n",
      "SAMPLE 58\n",
      "SAMPLE 59\n",
      "SAMPLE 60\n",
      "SAMPLE 61\n",
      "SAMPLE 62\n",
      "SAMPLE 63\n",
      "SAMPLE 64\n",
      "SAMPLE 65\n",
      "SAMPLE 66\n",
      "SAMPLE 67\n",
      "SAMPLE 68\n",
      "SAMPLE 69\n",
      "SAMPLE 70\n",
      "SAMPLE 71\n",
      "SAMPLE 72\n",
      "SAMPLE 73\n",
      "SAMPLE 74\n",
      "SAMPLE 75\n",
      "SAMPLE 76\n",
      "SAMPLE 77\n",
      "SAMPLE 78\n",
      "SAMPLE 79\n",
      "SAMPLE 80\n",
      "SAMPLE 81\n",
      "SAMPLE 82\n",
      "SAMPLE 83\n",
      "SAMPLE 84\n",
      "SAMPLE 85\n",
      "SAMPLE 86\n",
      "SAMPLE 87\n",
      "SAMPLE 88\n",
      "SAMPLE 89\n",
      "SAMPLE 90\n",
      "SAMPLE 91\n",
      "SAMPLE 92\n",
      "SAMPLE 93\n",
      "SAMPLE 94\n",
      "SAMPLE 95\n",
      "SAMPLE 96\n",
      "SAMPLE 97\n",
      "SAMPLE 98\n",
      "SAMPLE 99\n",
      "SAMPLE 100\n",
      "SAMPLE 101\n",
      "SAMPLE 102\n",
      "SAMPLE 103\n",
      "SAMPLE 104\n",
      "SAMPLE 105\n",
      "SAMPLE 106\n",
      "SAMPLE 107\n",
      "SAMPLE 108\n",
      "SAMPLE 109\n",
      "SAMPLE 110\n",
      "SAMPLE 111\n",
      "SAMPLE 112\n",
      "SAMPLE 113\n",
      "SAMPLE 114\n",
      "SAMPLE 115\n",
      "SAMPLE 116\n",
      "SAMPLE 117\n",
      "SAMPLE 118\n",
      "SAMPLE 119\n",
      "SAMPLE 120\n",
      "SAMPLE 121\n",
      "SAMPLE 122\n",
      "SAMPLE 123\n",
      "SAMPLE 124\n",
      "SAMPLE 125\n",
      "SAMPLE 126\n",
      "SAMPLE 127\n",
      "SAMPLE 128\n",
      "SAMPLE 129\n",
      "SAMPLE 130\n",
      "SAMPLE 131\n",
      "SAMPLE 132\n",
      "SAMPLE 133\n",
      "SAMPLE 134\n",
      "SAMPLE 135\n",
      "SAMPLE 136\n",
      "SAMPLE 137\n",
      "SAMPLE 138\n",
      "SAMPLE 139\n",
      "SAMPLE 140\n",
      "SAMPLE 141\n",
      "SAMPLE 142\n",
      "SAMPLE 143\n",
      "SAMPLE 144\n",
      "SAMPLE 145\n",
      "SAMPLE 146\n",
      "SAMPLE 147\n",
      "SAMPLE 148\n",
      "SAMPLE 149\n",
      "SAMPLE 150\n",
      "SAMPLE 151\n",
      "SAMPLE 152\n",
      "SAMPLE 153\n",
      "SAMPLE 154\n",
      "SAMPLE 155\n",
      "SAMPLE 156\n",
      "SAMPLE 157\n",
      "SAMPLE 158\n",
      "SAMPLE 159\n",
      "SAMPLE 160\n",
      "SAMPLE 161\n",
      "SAMPLE 162\n",
      "SAMPLE 163\n",
      "SAMPLE 164\n",
      "SAMPLE 165\n",
      "SAMPLE 166\n",
      "SAMPLE 167\n",
      "SAMPLE 168\n",
      "SAMPLE 169\n",
      "SAMPLE 170\n",
      "SAMPLE 171\n",
      "SAMPLE 172\n",
      "SAMPLE 173\n",
      "SAMPLE 174\n",
      "SAMPLE 175\n",
      "SAMPLE 176\n",
      "SAMPLE 177\n",
      "SAMPLE 178\n",
      "SAMPLE 179\n",
      "SAMPLE 180\n",
      "SAMPLE 181\n",
      "SAMPLE 182\n",
      "SAMPLE 183\n",
      "SAMPLE 184\n",
      "SAMPLE 185\n",
      "SAMPLE 186\n",
      "SAMPLE 187\n",
      "SAMPLE 188\n",
      "SAMPLE 189\n",
      "SAMPLE 190\n",
      "SAMPLE 191\n",
      "SAMPLE 192\n",
      "SAMPLE 193\n",
      "SAMPLE 194\n",
      "SAMPLE 195\n",
      "SAMPLE 196\n",
      "SAMPLE 197\n",
      "SAMPLE 198\n",
      "SAMPLE 199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Choose the number of iterations you want and run the\n",
    "n_iterations = 200\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    print('SAMPLE',i)\n",
    "    resampled_data = resample(df_data, replace=True)\n",
    "    FLs,AFBs,S3s,S4s,S5s,S7s,S8s,S9s = cal_observables(resampled_data, verbose = False)\n",
    "    addToFile('Bootstrap/FLs.csv',','.join(list(map(str,FLs))))\n",
    "    addToFile('Bootstrap/AFBs.csv',','.join(list(map(str,AFBs))))\n",
    "    addToFile('Bootstrap/S3s.csv',','.join(list(map(str,S3s))))\n",
    "    addToFile('Bootstrap/S4s.csv',','.join(list(map(str,S4s))))\n",
    "    addToFile('Bootstrap/S5s.csv',','.join(list(map(str,S5s))))\n",
    "    addToFile('Bootstrap/S7s.csv',','.join(list(map(str,S7s))))\n",
    "    addToFile('Bootstrap/S8s.csv',','.join(list(map(str,S8s))))\n",
    "    addToFile('Bootstrap/S9s.csv',','.join(list(map(str,S9s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9dd5217a0dde95d381641731e639fd09a35f02e990bc29f8ba4a4a2775dc0bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
